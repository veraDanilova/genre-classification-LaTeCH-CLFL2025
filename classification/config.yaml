bert-base-historic-multilingual-cased:
  learning_rate: 1e-5,
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  num_train_epochs: 5
  weight_decay: 0.01
  evaluation_strategy: "epoch"
  save_strategy: "epoch"
  load_best_model_at_end: True